[
    {
        "DescargasPDFs/Universal coalgebra: a theory of systems.pdf": {
            "keywords": [],
            "abstract": "",
            "introduction": "",
            "conclusions": ""
        }
    },
    {
        "DescargasPDFs/Fast Automatic Generation of DSP Algorithms.pdf": {
            "keywords": "",
            "abstract": "SPIRAL is a generator of optimized, platform-adapted libraries for digital signal processing algorithms. SPIRAL's strategy translates the implementation task into a search in an expanded space of alternatives. These result from the many degrees of freedom in the DSP algorithm itself and in the various coding choices. This paper describes the framework to represent and generate efficiently these alternatives: the formula generator module in SPIRAL. We also address the search module that works in tandem with the formula generator in a feedback loop to find optimal implementations. These modules are implemented using the computer algebra system GAP/AREP.",
            "introduction": "SPIRAL,",
            "conclusions": ""
        }
    },
    {
        "DescargasPDFs/Efficient variants of the ICP algorithm.pdf": {
            "keywords": "",
            "abstract": "The ICP (Iterative Closest Point) algorithm is widely used for geometric alignment of three-dimensional models when an initial estimate of the relative pose is known. Many variants of ICP have been proposed, affecting all phases of the algorithm from the selection and matching of points to the minimization strategy. We enumerate and classify many of these variants, and evaluate their effect on the speed with which the correct alignment is reached. In order to improve convergence for nearly-flat meshes with small features, such as inscribed surfaces, we introduce a new variant based on uniform sampling of the space of normals. We conclude by proposing a combination of ICP variants optimized for high speed. We demonstrate an implementation that is able to align two range images in a few tens of milliseconds, assuming a good initial guess. This capability has potential application to real-time 3D model acquisition and model-based tracking.",
            "introduction": "The ICP (originally Iterative Closest Point, though Iterative Corresponding Point is perhaps a better expansion for the abbreviation) algorithm has become the dominant method for aligning threedimensional models based purely on the geometry, and sometimes color, of the meshes. The algorithm is widely used for registering the outputs of 3D scanners, which typically only scan an object from one direction at a time. ICP starts with two meshes and an initial guess for their relative rigid-body transform, and iteratively refines the transform by repeatedly generating pairs of corresponding points on the meshes and minimizing an error metric. Generating the initial alignment may be done by a variety of methods, such as tracking scanner position, identification and indexing of surface features",
            "conclusions": "We have classified and compared several ICP variants, focusing on the effect each has on convergence speed. We have introduced a new sampling method that helps convergence for scenes with small, sparse features. Finally, we have presented an optimized ICP algorithm that uses a constant-time variant for finding point pairs, resulting in a method that takes only a few tens of milliseconds to align two meshes.\nBecause the present comparisons have focused largely on the speed of convergence, we anticipate future surveys that focus on the stability and robustness of ICP variants. In addition, a better analysis of the effects of various kinds of noise and distortion would yield further insights into the best alignment algorithms for real-world, noisy scanned data. Algorithms that switch between variants, depending on the local error landscape and the probable presence of local minima, might also provide increased robustness."
        }
    },
    {
        "DescargasPDFs/A Differential Fault Attack Technique against SPN Structures, with Application to the AES and KHAZAD.pdf": {
            "keywords": "AES, Block Ciphers, Fault Attacks, Side-channel Attacks",
            "abstract": "In this paper we describe a differential fault attack technique working against Substitution-Permutation Networks, and requiring very few faulty ciphertexts. The fault model used is realistic, as we consider random faults affecting bytes (faults affecting one only bit are much harder to induce). We implemented our attack on a PC for both the AES and KHAZAD. We are able to break the AES-128 with only 2 faulty ciphertexts, assuming the fault occurs between the antepenultimate and the penultimate MixColumn; this is better than the previous fault attacks against AES[6,",
            "introduction": "The idea of using hardware faults happening during the execution of a cryptographic algorithm for breaking it (typically, for retrieving the key) was first suggested in 1997 by D. Boneh, R.A. DeMillo, and R.J. Lipton",
            "conclusions": ""
        }
    },
    {
        "DescargasPDFs/Visual Object Categorization using Distance-Based Discriminant Analysis.pdf": {
            "keywords": "KOSINOV, Serhiy, MARCHAND-MAILLET, St\u00e9phane, PUN, Thierry. Visual object categorization using distance-based discriminant analysis. In: Proceedings of the 4th International Workshop on Multimedia Data and Document Engineering. Washington (DC). [s.l.] : [s.n.], 2004",
            "abstract": "This paper formulates the problem of object categorization in the discriminant analysis framework focusing on transforming visual feature data so as to make it conform to the compactness hypothesis in order to improve categorization accuracy. The sought transformation, in turn, is found as a solution to an optimization problem formulated in terms of inter-observation distances only, using the technique of iterative majorization. The proposed approach is suitable for both binary and multiple-class categorization problems, and can be applied as a dimensionality reduction technique. In the latter case, the number of discriminative features is determined automatically since the process of feature extraction is fully embedded in the optimization procedure. Performance tests validate our method on a number of benchmark data sets from the UCI repository, while the experiments in the application of visual object and contentbased image categorization demonstrate very competitive results, asserting the method's capability of producing semantically relevant matches that share the same or synonymous vocabulary with the query category and allowing multiple pertinent category assignment. 8 @9 is a weight of the Huber function majorizer, as defined in [17],\nand is a constant that collects all of the terms that are irrelevant from the point of view of minimization with respect to \u00a9 (see\nwhere % is a square symmetric design matrix, as specified in\nAs for e k G A \u00a9 DC , we start out by expressing its every term using a second order Taylor series expansion of the logarithm function around a supporting point \u00a4 \u00a9 . In the resulting formulation, the sum of Euclidean distances can be majorized by a rule based on the Cauchy-Schwarz inequality\n\u00a3 s",
            "introduction": "Object categorization, as a fundamental computer vision problem, has long been a major focus of ongoing research, which lead to the development of a variety of methods and techniques proposed to date, e.g.,",
            "conclusions": ""
        }
    }
]